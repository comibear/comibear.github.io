---
title: "[Paper Review] REALM: Retrieval-Augmented Language Model Pre-Training"
description: "Paper Review for REALM"
writer: Sangyun Won
categories: [AI, Paper Review]
tags: [AI]
image:
  path: https://github.com/user-attachments/assets/e0f3409d-c116-47f5-bab3-0fc367d9e2cf
  alt: Paper Review for REALM

math: true
toc: true
toc_sticky: true

date: 2024-09-26
last_modified_at: 2024-09-26
---

<style>
  figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}
.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}
</style>

<figure>
  <a href="https://arxiv.org/pdf/2002.08909" class="bookmark source">
    <div class="bookmark-info">
      <div class="bookmark-text">
        <div class="bookmark-title">REALM: Retrieval-Augmented Language Model Pre-Training</div>
        <div class="bookmark-description">arxiv pdf link for REALM</div>
      </div>
    </div>
  </a>
</figure>

## 0. Abstract
지금까지 여러 LM pre-training 은 엄청나게 많은 양의 지식을 학습하기 위해서 진행되어 왔으며, 이는 NLP task 중에서도 QA task 에 매우 중대한 영향을 주었다. 하지만, 이 지식들은 암시적으로 모델의 파라미터에 저장되어 있으며, 더 많은 지식을 학습하기 위해서는 더 큰 network 이 필요하다. 지식을 더욱 