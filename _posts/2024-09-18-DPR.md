---
title: "[Paper Review] Dense Passage Retrieval for Open-Domain Question Answering"
description: "Paper Review for DPR model"
writer: Sangyun Won
categories: [AI, Paper Review]
tags: [AI]
image:
  path: https://github.com/user-attachments/assets/544ee579-860b-4189-bdd6-8b3a3c626259
  alt: Paper Review for DPR model

math: true
toc: true
toc_sticky: true

date: 2024-09-18
last_modified_at: 2024-09-18
---

<style>
  figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}
.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}
</style>

<figure>
  <a href="https://arxiv.org/pdf/2004.04906" class="bookmark source">
    <div class="bookmark-info">
      <div class="bookmark-text">
        <div class="bookmark-title">Dense Passage Retrieval for Open-Domain Question Answering</div>
        <div class="bookmark-description">arxiv pdf link for DPR</div>
      </div>
    </div>
  </a>
</figure>

## 0. Abstract

`Open-domain question answering` 은 답변에 효과적인 passage를 `retrieval` 하는 방식에 의존한다. 이 방식은 지금까지 `TF-IDF`, `BM25`와 같은 `sparse vector space`를 생성하는 방법에 기인해 왔다. 본 논문에서는 이 `retrieval`을 위한 vector representation이 적은 수의 `question & passage`를 사용한 `dual-encoder framework`를 이용하여, `dense representation`으로도 사실상 가능하다는 것을 보인다.

광범위한 `open-domain QA dataset`을 이용하여 평가했을 때, 본 논문의 `dense retriever`은 상위 20개의 `retrieval` 정확도에서 기존의 `Lucene-BM25` 시스템 절대적으로 9% ~ 19% 능가했다. 또한, 이는 `open-domain QA` 에서 새로운 `SOTA`를 달성했다.

## 1. Introduction

`QA (Open-domain Question Answering)` 은 거대한 문서의 집합을 사용하여 `factoid question`에 답변하는 task이다. 이전의 `QA system`은 다소 복잡하고, 다양한 요소로 이루어져 있었다. 하지만 `Comprehension model`의 발달로 인해, 매우 간단한 `two-stage framework`로 나누어졌다.

1. **context retriever이 먼저 답변을 위한 passage들의 작은 집합을 선택한다.**

2. **그리고 reader이 retrieved 된 context들을 분석하여 올바른 정답을 도출한다.**

물론 QA task를 machine reading만의 task로 바라보는 관점 또한 충분히 고려할 만 하지만, huge performance degradation의 사례가 존재하기에, retrieval에 대한 향상이 필요하다고 여겨진다.

QA에서 retrieval은 주로 TF-IDF 이나 BM25로 구현되어 왔는데, 이는 keyword 를 중점으로 sparse vector로 표현하는 방법이였다. 반대로, dense vector을 latent semantic encoding 을 활용하여 앞선 sparse vector과는 상보적인 관계에 있다.

예를 들어 아래와 같은 예시를 살펴보자.

> _<span style="color:red;">**Q : Who is the bad guy in lord of the rings?**</span>_ <br><br>_<span style="color:blue;">**Useful context : Sala Baker is best known for portraying the villain Sauron in the Lord of the Rings trilogy.**</span>_

`Term-based system`은 _villain_ 과 *bad guy*에 대한 `semantic similarity`를 가지고 있지 않기 떄문에, 해당 `context`를 `retrieval` 하기 어렵지만, `dense retrieval system`은 이 두 단어를 연결지어 해당 `context`를 `reteival` 할 가능성이 높다.

더 나아가서 `Dense encoding` 은 `learable` 하기 때문에, 특정 task에 대해 specific 하게 학습하여 유연성 또한 가지고 있다. 이런 과정은 `MIPS (maximum inner product search) Algorithm`을 통해서 계산된다.

그러나, 일반적으로 좋은 `dense vector representation`을 학습하는 것은 큰 수의 `question & context pair` 이 필요하다고 여겨져 왔다. `Dense retrieval` 방법은 `TF-IDF`/`BM25`와 같은 고전 방식을 능가하지 못했었지만, ICT (inverse cloze task) training을 이용한 모델인 `ORQA`가 처음으로 이 방식을 능가하게 되었다.

> 여기서 `ICT (inverse cloze task)` 란, `context` 내에서 특정 `sentence`를 추출하여, 해당 `sentence` 가 어느 `context`에 속하는지를 학습하는 것이다.

하지만, 앞선 `ORQA`의 성능에도 불구하고, `multiple domain` 상에서의 SOTA를 달성하기에는 2가지 부분에서 문제점이 있었다.

1. **ICT는 computationally intensive 하고, 단순히 sentence를 matching 시키는 것이 Question anwsering에 효과적이라는 것이 명확하지 않다.**
2. **context encoder은 question-answer 쌍을 이용해 fine-tuned 되지 않았기 때문에, 해당 encoder을 통한 representation이 최적의 값이 아닐 수 있다.**

본 논문에서는,
