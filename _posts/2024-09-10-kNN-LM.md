---
title: "[Paper Review] Generalization Through Memorization: Nearest Neighbor Language Models"
description: "Paper Review for kNN-LM model"
writer: Sangyun Won
categories: [AI, Paper Review]
tags: [AI]
image:
  path: https://github.com/user-attachments/assets/f44a25a1-dc34-46d6-b024-8a1a881f5953
  alt: Paper Review for kNN-LM model

math: true
toc: true
toc_sticky: true

date: 2024-09-10
last_modified_at: 2024-09-10
---

<style>
html {
	-webkit-print-color-adjust: exact;
}
* {
	box-sizing: border-box;
	-webkit-print-color-adjust: exact;
}

html,
body {
	margin: 0;
	padding: 0;
}
@media only screen {
	body {
		margin: 2em auto;
		max-width: 900px;
		color: rgb(55, 53, 47);
	}
}

body {
	line-height: 1.5;
	white-space: pre-wrap;
}

a,
a.visited {
	color: inherit;
	text-decoration: underline;
}

.pdf-relative-link-path {
	font-size: 80%;
	color: #444;
}

h1,
h2,
h3 {
	letter-spacing: -0.01em;
	line-height: 1.2;
	font-weight: 600;
	margin-bottom: 0;
}

.page-title {
	font-size: 2.5rem;
	font-weight: 700;
	margin-top: 0;
	margin-bottom: 0.75em;
}

h1 {
	font-size: 1.875rem;
	margin-top: 1.875rem;
}

h2 {
	font-size: 1.5rem;
	margin-top: 1.5rem;
}

h3 {
	font-size: 1.25rem;
	margin-top: 1.25rem;
}

.source {
	border: 1px solid #ddd;
	border-radius: 3px;
	padding: 1.5em;
	word-break: break-all;
}

.callout {
	border-radius: 3px;
	padding: 1rem;
}

figure {
	margin: 1.25em 0;
	page-break-inside: avoid;
}

figcaption {
	opacity: 0.5;
	font-size: 85%;
	margin-top: 0.5em;
}

mark {
	background-color: transparent;
}

.indented {
	padding-left: 1.5em;
}

hr {
	background: transparent;
	display: block;
	width: 100%;
	height: 1px;
	visibility: visible;
	border: none;
	border-bottom: 1px solid rgba(55, 53, 47, 0.09);
}

img {
	max-width: 100%;
}

@media only print {
	img {
		max-height: 100vh;
		object-fit: contain;
	}
}

@page {
	margin: 1in;
}

.collection-content {
	font-size: 0.875rem;
}

.column-list {
	display: flex;
	justify-content: space-between;
}

.column {
	padding: 0 1em;
}

.column:first-child {
	padding-left: 0;
}

.column:last-child {
	padding-right: 0;
}

.table_of_contents-item {
	display: block;
	font-size: 0.875rem;
	line-height: 1.3;
	padding: 0.125rem;
}

.table_of_contents-indent-1 {
	margin-left: 1.5rem;
}

.table_of_contents-indent-2 {
	margin-left: 3rem;
}

.table_of_contents-indent-3 {
	margin-left: 4.5rem;
}

.table_of_contents-link {
	text-decoration: none;
	opacity: 0.7;
	border-bottom: 1px solid rgba(55, 53, 47, 0.18);
}

table,
th,
td {
	border: 1px solid rgba(55, 53, 47, 0.09);
	border-collapse: collapse;
}

table {
	border-left: none;
	border-right: none;
}

th,
td {
	font-weight: normal;
	padding: 0.25em 0.5em;
	line-height: 1.5;
	min-height: 1.5em;
	text-align: left;
}

th {
	color: rgba(55, 53, 47, 0.6);
}

ol,
ul {
	margin: 0;
	margin-block-start: 0.6em;
	margin-block-end: 0.6em;
}

li > ol:first-child,
li > ul:first-child {
	margin-block-start: 0.6em;
}

ul > li {
	list-style: disc;
}

ul.to-do-list {
	padding-inline-start: 0;
}

ul.to-do-list > li {
	list-style: none;
}

.to-do-children-checked {
	text-decoration: line-through;
	opacity: 0.375;
}

ul.toggle > li {
	list-style: none;
}

ul {
	padding-inline-start: 1.7em;
}

ul > li {
	padding-left: 0.1em;
}

ol {
	padding-inline-start: 1.6em;
}

ol > li {
	padding-left: 0.2em;
}

.mono ol {
	padding-inline-start: 2em;
}

.mono ol > li {
	text-indent: -0.4em;
}

.toggle {
	padding-inline-start: 0em;
	list-style-type: none;
}

/* Indent toggle children */
.toggle > li > details {
	padding-left: 1.7em;
}

.toggle > li > details > summary {
	margin-left: -1.1em;
}

.selected-value {
	display: inline-block;
	padding: 0 0.5em;
	background: rgba(206, 205, 202, 0.5);
	border-radius: 3px;
	margin-right: 0.5em;
	margin-top: 0.3em;
	margin-bottom: 0.3em;
	white-space: nowrap;
}

.collection-title {
	display: inline-block;
	margin-right: 1em;
}

.page-description {
    margin-bottom: 2em;
}

.simple-table {
	margin-top: 1em;
	font-size: 0.875rem;
	empty-cells: show;
}
.simple-table td {
	height: 29px;
	min-width: 120px;
}

.simple-table th {
	height: 29px;
	min-width: 120px;
}

.simple-table-header-color {
	background: rgb(247, 246, 243);
	color: black;
}
.simple-table-header {
	font-weight: 500;
}

time {
	opacity: 0.5;
}

.icon {
	display: inline-block;
	max-width: 1.2em;
	max-height: 1.2em;
	text-decoration: none;
	vertical-align: text-bottom;
	margin-right: 0.5em;
}

img.icon {
	border-radius: 3px;
}

.user-icon {
	width: 1.5em;
	height: 1.5em;
	border-radius: 100%;
	margin-right: 0.5rem;
}

.user-icon-inner {
	font-size: 0.8em;
}

.text-icon {
	border: 1px solid #000;
	text-align: center;
}

.page-cover-image {
	display: block;
	object-fit: cover;
	width: 100%;
	max-height: 30vh;
}

.page-header-icon {
	font-size: 3rem;
	margin-bottom: 1rem;
}

.page-header-icon-with-cover {
	margin-top: -0.72em;
	margin-left: 0.07em;
}

.page-header-icon img {
	border-radius: 3px;
}

.link-to-page {
	margin: 1em 0;
	padding: 0;
	border: none;
	font-weight: 500;
}

p > .user {
	opacity: 0.5;
}

td > .user,
td > time {
	white-space: nowrap;
}

input[type="checkbox"] {
	transform: scale(1.5);
	margin-right: 0.6em;
	vertical-align: middle;
}

p {
	margin-top: 0.5em;
	margin-bottom: 0.5em;
}

.image {
	border: none;
	margin: 1.5em 0;
	padding: 0;
	border-radius: 0;
	text-align: center;
}

.code,
code {
	background: rgba(135, 131, 120, 0.15);
	border-radius: 3px;
	padding: 0.2em 0.4em;
	border-radius: 3px;
	font-size: 85%;
	tab-size: 2;
}

code {
	color: #eb5757;
}

.code {
	padding: 1.5em 1em;
}

.code-wrap {
	white-space: pre-wrap;
	word-break: break-all;
}

.code > code {
	background: none;
	padding: 0;
	font-size: 100%;
	color: inherit;
}

blockquote {
	font-size: 1.25em;
	margin: 1em 0;
	padding-left: 1em;
	border-left: 3px solid rgb(55, 53, 47);
}

.bookmark {
	text-decoration: none;
	max-height: 8em;
	padding: 0;
	display: flex;
	width: 100%;
	align-items: stretch;
}

.bookmark-title {
	font-size: 0.85em;
	overflow: hidden;
	text-overflow: ellipsis;
	height: 1.75em;
	white-space: nowrap;
}

.bookmark-text {
	display: flex;
	flex-direction: column;
}

.bookmark-info {
	flex: 4 1 180px;
	padding: 12px 14px 14px;
	display: flex;
	flex-direction: column;
	justify-content: space-between;
}

.bookmark-image {
	width: 33%;
	flex: 1 1 180px;
	display: block;
	position: relative;
	object-fit: cover;
	border-radius: 1px;
}

.bookmark-description {
	color: rgba(55, 53, 47, 0.6);
	font-size: 0.75em;
	overflow: hidden;
	max-height: 4.5em;
	word-break: break-word;
}

.bookmark-href {
	font-size: 0.75em;
	margin-top: 0.25em;
}

.sans { font-family: ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol"; }
.code { font-family: "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace; }
.serif { font-family: Lyon-Text, Georgia, ui-serif, serif; }
.mono { font-family: iawriter-mono, Nitti, Menlo, Courier, monospace; }
.pdf .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK JP'; }
.pdf:lang(zh-CN) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK SC'; }
.pdf:lang(zh-TW) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK TC'; }
.pdf:lang(ko-KR) .sans { font-family: Inter, ui-sans-serif, -apple-system, BlinkMacSystemFont, "Segoe UI Variable Display", "Segoe UI", Helvetica, "Apple Color Emoji", Arial, sans-serif, "Segoe UI Emoji", "Segoe UI Symbol", 'Twemoji', 'Noto Color Emoji', 'Noto Sans CJK KR'; }
.pdf .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .code { font-family: Source Code Pro, "SFMono-Regular", Menlo, Consolas, "PT Mono", "Liberation Mono", Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.pdf .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK JP'; }
.pdf:lang(zh-CN) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK SC'; }
.pdf:lang(zh-TW) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK TC'; }
.pdf:lang(ko-KR) .serif { font-family: PT Serif, Lyon-Text, Georgia, ui-serif, serif, 'Twemoji', 'Noto Color Emoji', 'Noto Serif CJK KR'; }
.pdf .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK JP'; }
.pdf:lang(zh-CN) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK SC'; }
.pdf:lang(zh-TW) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK TC'; }
.pdf:lang(ko-KR) .mono { font-family: PT Mono, iawriter-mono, Nitti, Menlo, Courier, monospace, 'Twemoji', 'Noto Color Emoji', 'Noto Sans Mono CJK KR'; }
.highlight-default {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.highlight-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.highlight-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.highlight-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.highlight-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.highlight-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.highlight-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.highlight-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.highlight-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.highlight-default_background {
	color: rgba(55, 53, 47, 1);
}
.highlight-gray_background {
	background: rgba(241, 241, 239, 1);
}
.highlight-brown_background {
	background: rgba(244, 238, 238, 1);
}
.highlight-orange_background {
	background: rgba(251, 236, 221, 1);
}
.highlight-yellow_background {
	background: rgba(251, 237, 214, 1);
}
.highlight-teal_background {
	background: rgba(237, 243, 236, 1);
}
.highlight-blue_background {
	background: rgba(231, 243, 248, 1);
}
.highlight-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.highlight-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.highlight-red_background {
	background: rgba(253, 235, 236, 1);
}
.block-color-default {
	color: inherit;
	fill: inherit;
}
.block-color-gray {
	color: rgba(120, 119, 116, 1);
	fill: rgba(120, 119, 116, 1);
}
.block-color-brown {
	color: rgba(159, 107, 83, 1);
	fill: rgba(159, 107, 83, 1);
}
.block-color-orange {
	color: rgba(217, 115, 13, 1);
	fill: rgba(217, 115, 13, 1);
}
.block-color-yellow {
	color: rgba(203, 145, 47, 1);
	fill: rgba(203, 145, 47, 1);
}
.block-color-teal {
	color: rgba(68, 131, 97, 1);
	fill: rgba(68, 131, 97, 1);
}
.block-color-blue {
	color: rgba(51, 126, 169, 1);
	fill: rgba(51, 126, 169, 1);
}
.block-color-purple {
	color: rgba(144, 101, 176, 1);
	fill: rgba(144, 101, 176, 1);
}
.block-color-pink {
	color: rgba(193, 76, 138, 1);
	fill: rgba(193, 76, 138, 1);
}
.block-color-red {
	color: rgba(212, 76, 71, 1);
	fill: rgba(212, 76, 71, 1);
}
.block-color-default_background {
	color: inherit;
	fill: inherit;
}
.block-color-gray_background {
	background: rgba(241, 241, 239, 1);
}
.block-color-brown_background {
	background: rgba(244, 238, 238, 1);
}
.block-color-orange_background {
	background: rgba(251, 236, 221, 1);
}
.block-color-yellow_background {
	background: rgba(251, 237, 214, 1);
}
.block-color-teal_background {
	background: rgba(237, 243, 236, 1);
}
.block-color-blue_background {
	background: rgba(231, 243, 248, 1);
}
.block-color-purple_background {
	background: rgba(244, 240, 247, 0.8);
}
.block-color-pink_background {
	background: rgba(249, 238, 243, 0.8);
}
.block-color-red_background {
	background: rgba(253, 235, 236, 1);
}
.select-value-color-uiBlue { background-color: rgba(35, 131, 226, .07); }
.select-value-color-pink { background-color: rgba(245, 224, 233, 1); }
.select-value-color-purple { background-color: rgba(232, 222, 238, 1); }
.select-value-color-green { background-color: rgba(219, 237, 219, 1); }
.select-value-color-gray { background-color: rgba(227, 226, 224, 1); }
.select-value-color-transparentGray { background-color: rgba(227, 226, 224, 0); }
.select-value-color-translucentGray { background-color: rgba(0, 0, 0, 0.06); }
.select-value-color-orange { background-color: rgba(250, 222, 201, 1); }
.select-value-color-brown { background-color: rgba(238, 224, 218, 1); }
.select-value-color-red { background-color: rgba(255, 226, 221, 1); }
.select-value-color-yellow { background-color: rgba(249, 228, 188, 1); }
.select-value-color-blue { background-color: rgba(211, 229, 239, 1); }
.select-value-color-pageGlass { background-color: undefined; }
.select-value-color-washGlass { background-color: undefined; }

.checkbox {
	display: inline-flex;
	vertical-align: text-bottom;
	width: 16;
	height: 16;
	background-size: 16px;
	margin-left: 2px;
	margin-right: 5px;
}

.checkbox-on {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20width%3D%2216%22%20height%3D%2216%22%20fill%3D%22%2358A9D7%22%2F%3E%0A%3Cpath%20d%3D%22M6.71429%2012.2852L14%204.9995L12.7143%203.71436L6.71429%209.71378L3.28571%206.2831L2%207.57092L6.71429%2012.2852Z%22%20fill%3D%22white%22%2F%3E%0A%3C%2Fsvg%3E");
}

.checkbox-off {
	background-image: url("data:image/svg+xml;charset=UTF-8,%3Csvg%20width%3D%2216%22%20height%3D%2216%22%20viewBox%3D%220%200%2016%2016%22%20fill%3D%22none%22%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%3Crect%20x%3D%220.75%22%20y%3D%220.75%22%20width%3D%2214.5%22%20height%3D%2214.5%22%20fill%3D%22white%22%20stroke%3D%22%2336352F%22%20stroke-width%3D%221.5%22%2F%3E%0A%3C%2Fsvg%3E");
}

</style>

## 0. Abstract 🎬

`kNN-LM` 은 `pre-train` 된 LM을 선형적으로 kNN 알고리즘과 결합하여 확장한 모델이다. `pre-trained LM`을 이용해서 input 데이터가 `latent space` 로 임베딩 되게 되는데, 이 `latent space` 상의 벡터 간의 거리를 통해서 가장 가까운 k 개의 후보를 정하게 된다. 이는 임의의 데이터셋 (including training data) 을 통해서 가능하다.

이 방식을 `Wikitext-103LM` 에 적용함으로써, 이 논문에서 소개하는 모델은 SOTA를 달성했으며, 추가적인 training 없이도 15.79의 `perplexity`로 2.9 point나 줄이는 효과를 보였다. 또한, 이 접근법은 더 큰 훈련 데이터셋, 그리고 다른 `domain` 으로의 적용 역시 효과적으로 수행할 수 있었다.

질적으로는, 이 모델은 생소한 표현들에 대해서 더욱 효과적인 모습을 보였고, 특히 `factual knowledege` 에 대해서 효과적이였다. 동시에 이 연구는 LM 의 근본적인 task 인 `next token prediction` 보다 `sequences 간의 similarity` 를 학습하는 것이 더 효과적인 접근 방식임을 의미하기도 한다.

## 1. Introduction ☕️

Language Model 은 일반적으로 아래의 2가지 task를 목표로 한다.

**1. 즉 문장의 prefix를 n차원 벡터로 나타낸다. (정확히는 고정 크기의 representation)**

**2. 이렇게 만들어진 latent space에서의 값을 이용해서 다음 단어를 예측한다.**

본 논문에서는 첫번째 task가 두번째 task 보다 쉬운 task라는 가정 하에 접근했다. 예를 들어, "_Dickens is the author of_" 라는 문장과 "_Dickens wrote_" 라는 문장을 보았을 때, 그 후에 올 단어를 예측하지 못하더라도 두 문장이 같은 뜻을 내포하고 있음은 누구나 알 수 있다. 실험적으로도, `prefix embedding`에 대해 kNN을 적용시킨 결과, 성능이 향상됨을 통해 LM이 첫번째 task에 더 효과적이라는 강력한 증거를 제시한다.

`3-billion`개의 `token`을 모델의 학습 데이터로 사용하는 것보다, `100-million`개의 `token`을 이용해 학습하고 3-billion개의 `token`을 가지는 `dataset(documents)`을 이 모델에 적용하는 것이 더 높은 성능을 보였다. 이는 곧 Large dataset을 사용하는 LM에 대한 새로운 방향성을 제시한다. 비슷하게, 단순히 `datastore` 에 다른 domain의 데이터를 삽입하는 것만으로도 `multiple domain`에서도 효과적인 성능을 보였다.

![image](https://github.com/user-attachments/assets/f44a25a1-dc34-46d6-b024-8a1a881f5953)

마지막으로, 이 모델은 명시적 기억에 대한 접근 (datastore이라는 명시적인 데이터) 을 통해 `long-tail patterns` (예를 들어 `Factual Knowledge`) 에 대해서 더욱 효과적인 것을 발견했다.

## 2. Nearest Neighbor Language Modeling 🧐

LM은 기본적으로 `sequence`에 대한 확률을 할당한다. 다시 말해 $c_t = (w_1, \cdots , w_{t-1})$ 라는 `context (sequence)`가 주어져 있을 때, LM (autoregressive 한)은
$p(w_t|c_t)$를 계산해낸다.

*k*NN-LM은 `pre-trained LM`을 이용하여 `nearest-neighbors`를 검색(`retrieval`) 하여 `augument` 하는 과정을 내포하며, 이 datastore에는 `key-value` 형태의 `context-target` 쌍들이 저장되어 있다. (see Figure 1)

### Datastore

$f()$를 context $c$를 `fixed-length vector`로 `mapping`해주는 함수라고 가정해보자. 만약에 i번째 training data인 $(c_i, w_i) \in \mathcal{D}$가 주어졌을 때, 우리는 `datastore`을 다음과 같은 `key-value` 집합으로 정의할 수 있다.

$$
(\mathcal{K}, \mathcal{V}) = \{(f(c_i), w_i)|(c_i, w_i)\} \in \mathcal{D}
$$

### Inference

이 모델은 `input context` $x$가 주어졌을 때, $f(x)$를 통해 $p_{LM}(y|x)$에 대한 확률 분포를 계산하게 된다. 동시에 datastore 에 $f(x)$를 이용해 query를 보내게 되는데, `distance function`인 $d()$를 통해 `k-nearest neighbors`에 해당하는 집합 $\mathcal{N}$을 생성한다.
(본 논문에서는 `distance function`을 $L^2$ distance로 정의했다.)

그 후에는 `softmax`에 `negative distance`를 넣음으로써, 아래의 확률을 계산해낼 수 있다. (거리가 가까울수록 높은 확률의 정확도를 보인다.)

$$
p*{kNN}(y|x) \propto \sum_{(k*i, v_i) \in \mathcal{N}}{\mathbb{1}_{y=v_i} \, exp(-d(k_i, f(x)))}
$$

이를 선형적으로 기존 LM에 적용하게 되면, $\lambda$ 변수를 이용해서 다음과 같이 최종 `probability`를 정의할 수 있다.

$$p(y|x) = \lambda * p_{kNN}(y|x) + (1 - \lambda) * p_{LM}(y|x)$$

### Implementation

한 가지 문제점은, `Datastore` 이 `billion` 개의 데이터를 내포하고 있어 `computationally intensive` 하다는 것이다. 이를 극복하기 위해 `FAISS`라는 `open source library` 를 사용하여 고차원 상에서의 kNN을 효율적으로 계산하게 된다. 추가적으로, $L^2$ 이외에 `inner product distance` 라는 `distance function` 또한 존재하는데, 이 모델에서는 $L^2$ 방식이 더 높은 성능을 보였다.

### Related Cache Models

이전의 비슷한 접근 방식에서는, recent past에 대한 `caching` 을 통해서 최근의 데이터에 대해 더욱 효과적으로 계산하는 방식 또한 존재했다. 하지만 최근의 정보를 copy할 수 있는 `self-attention` 기법을 가진 `Transformer` 모델이 등장하고 나서, 이 방식은 인기를 잃게 되며, 얻을 수 있는 이익 또한 줄어들었다. 본 논문에서는 `training data`에 대한 명시적 기억을 위해 오로지 `training data`에 대해서만 `caching`하는 방식을 택하여 비슷한 cases에 대한 효율을 증대시켰다.

## 3. Experimental Setup 🥽

### Data

단순히 dataset에 대한 설명이기에 별도의 설명은 생략한다.

![image](https://github.com/user-attachments/assets/61a7608f-8383-4799-b01c-fdd0bd523ff9)

### Model Architecture

*k*NN-LM 모델은 `fixed-size context representations`을 생성하는 모델이라면 모두 호환이 가능하다. 이 모델은 현재 (당시) SOTA를 기록했던 `Decoder-only Transformer`을 사용한다. *k*NN-LM 모델은 모델의 기본 모델인 LM에 대한 훈련을 시행하지 않기 때문에, 기존 아키텍쳐와 최적화 방식을 그대로 사용했다.

`16 layer`, `each with 16 self-attention heads`, `1024 dimensional hidden states`, `4096 dimensional feedforward layers`, `247M parameters` 등을 사용하며 추가 정보는 아래와 같다.

![image](https://github.com/user-attachments/assets/0389fbaa-e033-4f79-9977-b2956de075fd)

### Evaluation

이 LM들은 `negative log-likelihood` 를 `loss function`으로 사용했으며, 모델의 평가 기준으로써 `perplexity`를 사용했다. (_살짝 첨언하자면, 최근 논문인 Mamba의 reject 원인으로 `perplexity`가 평가 기준이 되는 것은 정당하지 않다는 글을 본 것 같은데, 이때는 기준이 조금 달랐나보다._)

### *k*NN-LM

<figure id="8b48f93f-7612-4d74-8935-a028926a8762">
  <a href="https://facerain.github.io/nlp-tutorial-roadmap/" class="bookmark source">
    <div class="bookmark-info">
      <div class="bookmark-text">
        <div class="bookmark-title">[5분 NLP] NLP 공부 시작하기</div>
        <div class="bookmark-description">NLP 공부 어떻게 시작하면 좋을까요?</div>
      </div>
      <div class="bookmark-href">
        <img src="https://facerain.github.io/favicon.ico" class="icon bookmark-icon" alt="icon" />https://facerain.github.io/nlp-tutorial-roadmap/
      </div>
    </div>
    <img src="https://facerain.github.io/static/e14d9a9714a527a3420c0312b381ee9f/th.jpg" class="bookmark-image" alt="img"/>
  </a>
</figure>
